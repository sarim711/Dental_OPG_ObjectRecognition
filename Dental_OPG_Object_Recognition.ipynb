{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNU5LH/3b3xZ4JPkA6G+0/f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarim711/Dental_OPG_ObjectRecognition/blob/main/Dental_OPG_Object_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Ultralytics YOLOv8\n",
        "!pip install ultralytics\n",
        "\n",
        "# Import YOLO\n",
        "from ultralytics import YOLO\n",
        "import os"
      ],
      "metadata": {
        "id": "GfwKQ4L_Npyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the zipfile module\n",
        "import zipfile\n",
        "\n",
        "# Specify the path to the zip file\n",
        "zip_path = '/content/Dental OPG (Object Detection).zip'\n",
        "\n",
        "# Specify the directory where you want to extract the files\n",
        "extract_path = '/content/'\n",
        "\n",
        "# Unzip the file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "print(\"Unzipping completed!\")"
      ],
      "metadata": {
        "id": "f49g4sHfNsg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paths = [\n",
        "    '/content/Dental OPG (Object Detection)/Augmented Dataset/train/images',\n",
        "    '/content/Dental OPG (Object Detection)/Augmented Dataset/train/labels',\n",
        "    '/content/Dental OPG (Object Detection)/Augmented Dataset/valid/images',\n",
        "    '/content/Dental OPG (Object Detection)/Augmented Dataset/valid/labels',\n",
        "    '/content/Dental OPG (Object Detection)/Augmented Dataset/test/images',\n",
        "    '/content/Dental OPG (Object Detection)/Augmented Dataset/test/labels'\n",
        "]\n",
        "\n",
        "for path in paths:\n",
        "    if os.path.exists(path):\n",
        "        print(f\"{path}: Exists, contains {len(os.listdir(path))} files\")\n",
        "    else:\n",
        "        print(f\"{path}: Does not exist\")"
      ],
      "metadata": {
        "id": "eGGKvQkoNwhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "# Define the YAML content\n",
        "data_yaml = {\n",
        "    'train': '/content/Dental OPG (Object Detection)/Augmented Dataset/train/images',\n",
        "    'val': '/content/Dental OPG (Object Detection)/Augmented Dataset/valid/images',\n",
        "    'test': '/content/Dental OPG (Object Detection)/Augmented Dataset/test/images',\n",
        "    'nc': 6,\n",
        "    'names': ['HealthyT', 'C', 'Imp', 'BDR', 'Inf', 'Ft']\n",
        "\n",
        "}\n",
        "\n",
        "# Save to data.yaml\n",
        "with open('/content/data.yaml', 'w') as f:\n",
        "    yaml.dump(data_yaml, f, default_flow_style=False)\n",
        "\n",
        "# Verify the file\n",
        "with open('/content/data.yaml', 'r') as f:\n",
        "    print(f.read())\n"
      ],
      "metadata": {
        "id": "nX66r8AUN1Bd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a pretrained YOLOv8 model\n",
        "model = YOLO('yolov8l.pt')  # Use 'yolov8s.pt' for better accuracy if needed\n",
        "\n",
        "# Train the model\n",
        "model.train(\n",
        "    data='/content/data.yaml',  # Path to YAML file\n",
        "    epochs=100,                 # Number of epochs\n",
        "    batch=16,                   # Batch size (adjust for Colab GPU)\n",
        "    imgsz=640,                  # Image size\n",
        "    device='cuda',\n",
        "    lr0=0.01,\n",
        "    lrf=0.0001,\n",
        "    patience=20,                # Early stopping\n",
        "    project='/content/runs/train',  # Output directory\n",
        "    name='exp'                  # Experiment name\n",
        ")"
      ],
      "metadata": {
        "id": "9wdpd33PN3Z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained model\n",
        "model = YOLO('/content/runs/train/exp/weights/best.pt')\n",
        "\n",
        "# Evaluate on validation set\n",
        "metrics = model.val(data='/content/data.yaml')\n",
        "\n",
        "# Print key metrics\n",
        "print(f\"mAP@50: {metrics.box.map50}\")\n",
        "print(f\"mAP@50:95: {metrics.box.map}\")"
      ],
      "metadata": {
        "id": "UoyfuvPON6YZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run inference on test set\n",
        "results = model.predict(\n",
        "    source='/content/Dental OPG (Object Detection)/Augmented Dataset/test/images',\n",
        "    save=True,                    # Save predictions\n",
        "    save_txt=True,                # Save labels in YOLO format\n",
        "    project='/content/runs/predict',  # Output directory\n",
        "    name='exp'\n",
        ")"
      ],
      "metadata": {
        "id": "RnkxzBf2N9lH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_labels(label_path):\n",
        "    labels = []\n",
        "    with open(label_path, 'r') as file:\n",
        "        for line in file:\n",
        "            label = line.strip().split()\n",
        "            class_id = int(label[0])\n",
        "            x_center, y_center, width, height = map(float, label[1:])\n",
        "            labels.append((class_id, x_center, y_center, width, height))\n",
        "    return labels\n",
        "\n",
        "# cnvertir les coordonnées normalisées en pixels\n",
        "def convert_to_pixels(image_width, image_height, labels):\n",
        "    pixel_labels = []\n",
        "    for label in labels:\n",
        "        class_id, x_center, y_center, width, height = label\n",
        "        x_center_px = x_center * image_width\n",
        "        y_center_px = y_center * image_height\n",
        "        width_px = width * image_width\n",
        "        height_px = height * image_height\n",
        "        pixel_labels.append((class_id, x_center_px, y_center_px, width_px, height_px))\n",
        "    return pixel_labels\n",
        "\n",
        "# Fonction pour afficher l'image avec les box et les classes\n",
        "def draw_boxes(img, boxes, classes, color=(0, 255, 0), thickness=3, font_scale=1.0, font_thickness=2):\n",
        "    for box, class_id in zip(boxes, classes):\n",
        "        x_center, y_center, width, height = box\n",
        "        x1, y1 = int(x_center - width / 2), int(y_center - height / 2)\n",
        "        x2, y2 = int(x_center + width / 2), int(y_center + height / 2)\n",
        "        cv2.rectangle(img, (x1, y1), (x2, y2), color, thickness)\n",
        "\n",
        "        # Ajouter le texte pour la classe avec une taille de police plus grande\n",
        "        label = f\"Class {class_id}\"\n",
        "        cv2.putText(img, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, font_thickness)\n",
        "    return img\n",
        "\n",
        "# Dossier des images et labels\n",
        "test_path = '/content/Dental OPG (Object Detection)/Original Dataset'\n",
        "label_path = '/content/Dental OPG (Object Detection)/Original Dataset'\n",
        "\n",
        "# Lister toutes les images dans le répertoire\n",
        "all_images = [f for f in os.listdir(test_path) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
        "\n",
        "# Sélectionner un nombre d'images aléatoires\n",
        "random_images = random.sample(all_images, 3)\n",
        "\n",
        "# Effectuer les prédictions et comparer avec les vrais labels\n",
        "for image_name in random_images:\n",
        "    image_path = os.path.join(test_path, image_name)\n",
        "    label_name = image_name.replace('.jpg', '.txt').replace('.jpeg', '.txt').replace('.png', '.txt')\n",
        "    label_path_full = os.path.join(label_path, label_name)\n",
        "\n",
        "    # Charger l'image\n",
        "    img = cv2.imread(image_path)\n",
        "\n",
        "    # Obtenir les dimensions de l'image pour la conversion des coordonnées\n",
        "    image_height, image_width, _ = img.shape\n",
        "\n",
        "    # Charger les labels réels\n",
        "    true_labels = load_labels(label_path_full)\n",
        "\n",
        "    # Convertir les labels en coordonnées en pixels\n",
        "    true_labels_px = convert_to_pixels(image_width, image_height, true_labels)\n",
        "\n",
        "    # Faire une prédiction sur l'image\n",
        "    results = model(img)\n",
        "\n",
        "    # Récupérer les boîtes et les classes prédites\n",
        "    predicted_boxes = results[0].boxes.xywh.cpu().numpy()\n",
        "    predicted_classes = results[0].boxes.cls.cpu().numpy()\n",
        "\n",
        "    # Dessiner les boîtes et les classes sur l'image (Prédictions en vert, Vrais labels en rouge)\n",
        "    img_pred = draw_boxes(img.copy(), predicted_boxes, predicted_classes, color=(0, 255, 0), thickness=3, font_scale=1.2, font_thickness=3)\n",
        "    img_true = draw_boxes(img.copy(), [box[1:] for box in true_labels_px], [box[0] for box in true_labels_px], color=(0, 0, 255), thickness=3, font_scale=1.2, font_thickness=3)\n",
        "\n",
        "    # Afficher l'image avec les prédictions\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Afficher l'image avec les prédictions\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(cv2.cvtColor(img_pred, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(f\"Predictions for {image_name}\")\n",
        "\n",
        "    # Afficher l'image avec les vrais labels\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(cv2.cvtColor(img_true, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(f\"Ground Truth for {image_name}\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    # Comparaison des classes\n",
        "    print(f\"Comparing predictions with ground truth for {image_name}\")\n",
        "    print(\"Predictions:\")\n",
        "    print(predicted_classes)\n",
        "    print(\"True labels:\")\n",
        "    print([label[0] for label in true_labels_px])"
      ],
      "metadata": {
        "id": "vy1RNv6gOB7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "# Load the trained model\n",
        "model_path = '/content/runs/train/exp/weights/best.pt'\n",
        "if not os.path.exists(model_path):\n",
        "    print(f\"Model not found at {model_path}. Check the path or train the model.\")\n",
        "else:\n",
        "    model = YOLO(model_path)\n",
        "\n",
        "# Upload images\n",
        "print(\"Upload images for object detection:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Process and display each image\n",
        "for img_name, img_data in uploaded.items():\n",
        "    img = Image.open(BytesIO(img_data)).convert('RGB')\n",
        "    img_np = np.array(img)\n",
        "\n",
        "    # Run inference\n",
        "    results = model.predict(img_np, save=False, verbose=False)\n",
        "\n",
        "    # Display image with bounding boxes\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(img_np)\n",
        "    ax = plt.gca()\n",
        "\n",
        "    for result in results:\n",
        "        for box in result.boxes:\n",
        "            xywh = box.xywh.cpu().numpy()[0]\n",
        "            x, y, w, h = xywh\n",
        "            x1 = x - w / 2\n",
        "            y1 = y - h / 2\n",
        "            rect = plt.Rectangle((x1, y1), w, h, linewidth=2, edgecolor='r', facecolor='none')\n",
        "            ax.add_patch(rect)\n",
        "            class_id = int(box.cls)\n",
        "            class_name = result.names[class_id]\n",
        "            confidence = float(box.conf)\n",
        "            plt.text(x1, y1 - 10, f\"{class_name} ({confidence:.2f})\",\n",
        "                     color='r', fontsize=12, bbox=dict(facecolor='white', alpha=0.8))\n",
        "\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"Detections for {img_name}\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "1D1cFdijOF3k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}